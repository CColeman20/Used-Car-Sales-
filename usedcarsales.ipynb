{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid purple; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment 4</b>\n",
    "\n",
    "\n",
    "Thank you for the updates! You can find my new comments with digit 4. You did a great job here! You learned how to build and evaluate models to predict used car prices. You have successfully conducted EDA, handled missing values and outliers. You trained and tuned several models, compared their RMSE and speed, and chose the best model for the final testing. You learned how to prepare and encode large data and how to weigh training speed vs. prediction error, and why this matters in real-world applications. I hope you enjoyed this project! I do not have any questions, so the project can be accepted. Good luck! \n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid purple; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment 3</b>\n",
    "\n",
    "\n",
    "You almost finished it, great job! My new comments have digit 3. There are just a couple of issues this time. Would you please take a look?\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid purple; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment 2</b>\n",
    "\n",
    "\n",
    "Thank you for submitting the project! I appreciate the time you took to update it!  I've left a couple of new comments with digit 2. Would you please take a look? \n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid purple; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "Hi Chris! Congratulations on submitting another project! üéâ I will be using the standard the color marking:\n",
    "    \n",
    "\n",
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "\n",
    "Great solutions and ideas that can and should be used in the future are in green comments. Some of them are: \n",
    "    \n",
    "    \n",
    "- You have successfully prepared the subsets. It is important to split the data correctly in order to ensure there's no intersection;    \n",
    "\n",
    "    \n",
    "- Excluded several irrelevant columns;\n",
    "    \n",
    "    \n",
    "- Encoded cetegorical columns;    \n",
    "\n",
    "    \n",
    "- Trained two models, great!\n",
    "\n",
    "    \n",
    "\n",
    "</div>\n",
    "    \n",
    "<div style=\"border: 5px solid gold; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment </b>\n",
    "\n",
    "Yellow color indicates what should be optimized. This is not necessary, but it will be great if you make changes to this project. I've left several recommendations throughout the project. Please take a look.\n",
    " \n",
    "</div>\n",
    "<div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment </b>\n",
    "\n",
    "Issues that must be corrected to achieve accurate results are indicated in red comments. Please note that the project cannot be accepted until these issues are resolved. For instance,\n",
    "\n",
    "\n",
    "\n",
    "- Please try to explore the distributions and add conclusions. In real-world problems, the data is rarely clean. Displaying distributions help us evaluate the data, find outliers, identify the required preprocessing steps and understand feature relationships, which informs feature engineering. Feature engineering in some cases is a clue; \n",
    "\n",
    "    \n",
    "- There are several columns that can also be dropped. Please consider removing them to reduce computational cost;\n",
    "\n",
    "\n",
    "    \n",
    "- Check the data for the duplicates after you drop columns; \n",
    "    \n",
    "\n",
    "    \n",
    "- Please split the data first, only then we need to encode it to avoid data leakage;\n",
    "\n",
    "  \n",
    "    \n",
    "- According to the task, we are supposed to measure models' training and prediction speed. Would you please measure them separately for each model?\n",
    "\n",
    "\n",
    "    \n",
    "- Please add a conclusion about each model; \n",
    "\n",
    "    \n",
    "    \n",
    "- We also need to tune hyperparameters. We tune them to identify the hyperparameters that will yield the desired metric value. Would you try to implement it?  \n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "- Please don't use the test subset until the final test for the reason I stated in one of my comments;\n",
    "\n",
    "    \n",
    "    \n",
    "- In the very end of the project, choose the best model (the one that yielded the best RMSE or 2 if they have the same metric values) and run the final test;\n",
    "\n",
    "    \n",
    "    \n",
    "- Add the final conclusion please. A well-written conclusion shows how the project met its objectives and provides a concise and understandable summary for those who may not have been involved in the details of the project. \n",
    "\n",
    "\n",
    "There may be other issues that need your attention. I described everything in my comments.  \n",
    "</div>        \n",
    "<hr>\n",
    "    \n",
    "<font color='dodgerblue'>**To sum up:**</font> great job here! You demonstrated strong analytical and modeling skills by preparing the data, experimenting with multiple advanced models, and evaluating them with appropriate metrics. Please take a look at my comments and do not hesitate to ask questions if some of them seem unclear. I will wait the project for the second review üòä \n",
    "    \n",
    "\n",
    "<hr>\n",
    "    \n",
    "Please use some color other than those listed to highlight answers to my comments.\n",
    "I would also ask you **not to change, move or delete my comments** to make it easier for me to navigate during the next review.\n",
    "    \n",
    "<hr> \n",
    "    \n",
    "‚úçÔ∏è Here's a link to [Supervised Learning documenation sections](https://scikit-learn.org/stable/supervised_learning.html) that you may find useful.\n",
    "    \n",
    "<hr>\n",
    "    \n",
    "    \n",
    "üìå Please feel free to schedule a 1:1 sessions with our tutors or TAs Feel free to book 1-1 session [here](https://calendly.com/tripleten-ds-experts-team), join daily coworking sessions, or ask questions in the sprint channels on Discord if you need assistance üòâ \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rusty Bargain used car sales service is developing an app to attract new customers. In that app, you can quickly find out the market value of your car. You have access to historical data: technical specifications, trim versions, and prices. You need to build the model to determine the value. \n",
    "\n",
    "Rusty Bargain is interested in:\n",
    "\n",
    "- the quality of the prediction;\n",
    "- the speed of the prediction;\n",
    "- the time required for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "    \n",
    "Good introduction that reflects the core goals. Well done!  \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('/datasets/car_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24/03/2016 11:52</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>70435</td>\n",
       "      <td>07/04/2016 03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24/03/2016 10:58</td>\n",
       "      <td>18300</td>\n",
       "      <td>coupe</td>\n",
       "      <td>2011</td>\n",
       "      <td>manual</td>\n",
       "      <td>190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>audi</td>\n",
       "      <td>yes</td>\n",
       "      <td>24/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>66954</td>\n",
       "      <td>07/04/2016 01:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/03/2016 12:52</td>\n",
       "      <td>9800</td>\n",
       "      <td>suv</td>\n",
       "      <td>2004</td>\n",
       "      <td>auto</td>\n",
       "      <td>163</td>\n",
       "      <td>grand</td>\n",
       "      <td>125000</td>\n",
       "      <td>8</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>jeep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>90480</td>\n",
       "      <td>05/04/2016 12:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17/03/2016 16:54</td>\n",
       "      <td>1500</td>\n",
       "      <td>small</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>75</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>17/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>91074</td>\n",
       "      <td>17/03/2016 17:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31/03/2016 17:25</td>\n",
       "      <td>3600</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>69</td>\n",
       "      <td>fabia</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>skoda</td>\n",
       "      <td>no</td>\n",
       "      <td>31/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>60437</td>\n",
       "      <td>06/04/2016 10:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n",
       "0  24/03/2016 11:52    480         NaN              1993  manual      0   \n",
       "1  24/03/2016 10:58  18300       coupe              2011  manual    190   \n",
       "2  14/03/2016 12:52   9800         suv              2004    auto    163   \n",
       "3  17/03/2016 16:54   1500       small              2001  manual     75   \n",
       "4  31/03/2016 17:25   3600       small              2008  manual     69   \n",
       "\n",
       "   Model  Mileage  RegistrationMonth  FuelType       Brand NotRepaired  \\\n",
       "0   golf   150000                  0    petrol  volkswagen         NaN   \n",
       "1    NaN   125000                  5  gasoline        audi         yes   \n",
       "2  grand   125000                  8  gasoline        jeep         NaN   \n",
       "3   golf   150000                  6    petrol  volkswagen          no   \n",
       "4  fabia    90000                  7  gasoline       skoda          no   \n",
       "\n",
       "        DateCreated  NumberOfPictures  PostalCode          LastSeen  \n",
       "0  24/03/2016 00:00                 0       70435  07/04/2016 03:16  \n",
       "1  24/03/2016 00:00                 0       66954  07/04/2016 01:46  \n",
       "2  14/03/2016 00:00                 0       90480  05/04/2016 12:47  \n",
       "3  17/03/2016 00:00                 0       91074  17/03/2016 17:40  \n",
       "4  31/03/2016 00:00                 0       60437  06/04/2016 10:17  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   DateCrawled        354369 non-null  object\n",
      " 1   Price              354369 non-null  int64 \n",
      " 2   VehicleType        316879 non-null  object\n",
      " 3   RegistrationYear   354369 non-null  int64 \n",
      " 4   Gearbox            334536 non-null  object\n",
      " 5   Power              354369 non-null  int64 \n",
      " 6   Model              334664 non-null  object\n",
      " 7   Mileage            354369 non-null  int64 \n",
      " 8   RegistrationMonth  354369 non-null  int64 \n",
      " 9   FuelType           321474 non-null  object\n",
      " 10  Brand              354369 non-null  object\n",
      " 11  NotRepaired        283215 non-null  object\n",
      " 12  DateCreated        354369 non-null  object\n",
      " 13  NumberOfPictures   354369 non-null  int64 \n",
      " 14  PostalCode         354369 non-null  int64 \n",
      " 15  LastSeen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Power</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.0</td>\n",
       "      <td>354369.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4416.656776</td>\n",
       "      <td>2004.234448</td>\n",
       "      <td>110.094337</td>\n",
       "      <td>128211.172535</td>\n",
       "      <td>5.714645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50508.689087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4514.158514</td>\n",
       "      <td>90.227958</td>\n",
       "      <td>189.850405</td>\n",
       "      <td>37905.341530</td>\n",
       "      <td>3.726421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25783.096248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1067.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>125000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30165.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2700.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49413.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6400.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99998.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Price  RegistrationYear          Power        Mileage  \\\n",
       "count  354369.000000     354369.000000  354369.000000  354369.000000   \n",
       "mean     4416.656776       2004.234448     110.094337  128211.172535   \n",
       "std      4514.158514         90.227958     189.850405   37905.341530   \n",
       "min         0.000000       1000.000000       0.000000    5000.000000   \n",
       "25%      1050.000000       1999.000000      69.000000  125000.000000   \n",
       "50%      2700.000000       2003.000000     105.000000  150000.000000   \n",
       "75%      6400.000000       2008.000000     143.000000  150000.000000   \n",
       "max     20000.000000       9999.000000   20000.000000  150000.000000   \n",
       "\n",
       "       RegistrationMonth  NumberOfPictures     PostalCode  \n",
       "count      354369.000000          354369.0  354369.000000  \n",
       "mean            5.714645               0.0   50508.689087  \n",
       "std             3.726421               0.0   25783.096248  \n",
       "min             0.000000               0.0    1067.000000  \n",
       "25%             3.000000               0.0   30165.000000  \n",
       "50%             6.000000               0.0   49413.000000  \n",
       "75%             9.000000               0.0   71083.000000  \n",
       "max            12.000000               0.0   99998.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data exploration\n",
    "display(data.head())\n",
    "display(data.info())\n",
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "The data was successfully read, well done! \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 262\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "duplicates = data.duplicated().sum()\n",
    "print(f'Duplicates: {duplicates}')\n",
    "\n",
    "# Drop duplicates if any\n",
    "data = data.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    " # Handle Duplicates\n",
    "# We identify and remove duplicate rows to clean the data.\n",
    "duplicates = data.duplicated().sum()\n",
    "print(f'Number of Duplicates: {duplicates}')\n",
    "if duplicates > 0:\n",
    "    data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates after dropping columns: 73486\n"
     ]
    }
   ],
   "source": [
    "# Handle Missing Values\n",
    "# Handle Missing Values and Remove Irrelevant Columns\n",
    "\n",
    "# Drop irrelevant columns to reduce computation cost\n",
    "columns_to_drop = ['LastSeen', 'DateCreated', 'RegistrationYear', 'RegistrationMonth', 'PostalCode', 'NumberOfPictures', 'DateCrawled']\n",
    "data.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Define categorical columns to process (excluding now-dropped ones)\n",
    "categorical_cols = ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'Brand', 'NotRepaired']\n",
    "for col in categorical_cols:\n",
    "    if col in data.columns:\n",
    "        data[col].fillna('unknown', inplace=True)\n",
    "\n",
    "# Fill missing numerical values\n",
    "if 'Power' in data.columns:\n",
    "    data['Power'].fillna(data['Power'].median(), inplace=True)\n",
    "\n",
    "# After dropping columns, some previously unique rows may now be duplicates\n",
    "duplicates_after_dropping = data.duplicated().sum()\n",
    "print(f'Number of duplicates after dropping columns: {duplicates_after_dropping}')\n",
    "if duplicates_after_dropping > 0:\n",
    "    data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "\n",
    "- > `data = data.drop(['NumberOfPictures', 'PostalCode'], axis=1)`\n",
    "   \n",
    "Agreed! We don't need these columns. \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "- It's a good decision to fill in the gaps with some unique value, it's better than deleting them. Moreover, it is normal that sometimes sellers do not specify some information. The model should \"know\" about such cases. We even should not use median or mode. Even though the median does not skew the distribution, we have to many missing values to fill in because there is a risk of biasing the data.   \n",
    "    \n",
    "    \n",
    "</div>\n",
    "<div style=\"border: 5px solid gold; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "\n",
    "- You can then drop `RegistrationMonth`, `DateCreated`, `RegistrationYear`. It will significantly simplify the training process. \n",
    "\n",
    "    \n",
    "- `DateCreated`, however, can be used to calculate the publication period. The longer an active advertisement remains published, the less likely the car is being sold, likely due to an overpriced offer.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "- Consider comparing max dates in the `RegistrationYear` and  `DateCrawled` columns. Vehicle should not be registered after the data was downloaded :) \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "- Another option is to drop `VehicleType` and `Brand`, since we have `Model` that should reflect both. \n",
    "\n",
    "\n",
    "\n",
    "- > `data['Power'].fillna(data['Power'].median(), inplace=True)`\n",
    "\n",
    "Do we have any missing values here? \n",
    "\n",
    "\n",
    "\n",
    "- Consider analyzing categories as well. Petrol and gasoline refer to the same fuel, so we can use one of these categories. There are some other rare fuel types that can be dropped. If a category appears only in the training or validation subset, for instance, and we use `handle_unknown='ignore'`, the linear model might miss important signals in validation or make predictions with incomplete features thus breaking the assumptions of linearity. It may be helpful to make sure that training and validation subsets use the same feature columns after encoding. \n",
    "\n",
    "\n",
    "</div>\n",
    "<div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "\n",
    "- The `Model` column still has missing values.\n",
    "\n",
    "      \n",
    "- Are there any outliers in the data?  Please call the `describe` method and display charts. Drop abnormal values if they exist. Hint: `price` and `power` columns definitely have outliers.\n",
    "    \n",
    "\n",
    "\n",
    "- After removing unnecessary columns, it makes sense to check the data for duplicates again, as the dataset will later be splitted into training and test sets. Removing specific columns can cause previously distinct rows to become identical. If a dropped column contained unique values (ID or timestamp), removing it may make multiple rows appear the same.   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxplot for Car Prices:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Outlier Detection and Removal\n",
    "print('Boxplot for Car Prices:')\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=data['Price'])\n",
    "plt.title('Car Prices Boxplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxplot for Car Power:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Boxplot for Car Power:')\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=data['Power'])\n",
    "plt.title('Car Power Boxplot')\n",
    "plt.show()\n",
    "\n",
    "data = data[(data['Price'] > 100) & (data['Price'] < 100000)]\n",
    "data = data[(data['Power'] >= 50) & (data['Power'] < 1000)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment 2</b>\n",
    "    \n",
    "\n",
    "\n",
    "- > `data = data[(data['Power'] > 0) & (data['Power'] < 1000)]`\n",
    "                                                     \n",
    "                                                     \n",
    "What if the next minimum power value is 1 or 2?  Consider removing everything below 50. \n",
    "                                                     \n",
    "  \n",
    "- There are columns that should be deleted to reduce computational cost. These are:  `LastSeen`, `DateCreated`, `RegistrationYear`, `RegistrationMonth`, `PostalCode` and `NumberOfPictures`. After removing unnecessary columns, it makes sense to check the data for duplicates again, as the dataset will later be splitted into training and test sets. Removing specific columns can cause previously distinct rows to become identical. If a dropped column contained unique values (ID or timestamp), removing it may make multiple rows appear the same.   \n",
    "\n",
    "- After removing unnecessary columns, please drop duplicates again, as the dataset will later be splitted into training and test sets. If a dropped column contained unique values (ID or timestamp), removing it may make multiple rows appear the same, that's why we need to check for the duplicates again. \n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"border: 5px solid gold; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment 2 </b>\n",
    "    \n",
    "- You can drop `VehicleType` and `Brand` as well if you want, since we have `Model` that should reflect both. \n",
    "\n",
    "\n",
    "\n",
    "- You can also delete very rare model categories.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment 4 </b>\n",
    "    \n",
    "    \n",
    "Correct!    \n",
    "</div><div style=\"border: 5px solid red; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment 3 </b>\n",
    "    \n",
    "- Please exclude irrelevant columns. We have too many columns with a huge number of categories. The Kernel will die. So, to reduce computation cost, we exclude irrelevant column. I mentioned them in the comment above.\n",
    "\n",
    "\n",
    "- After  you do this, please drop duplicates from the dataframe because new duplicates may appear after we exclude columns. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "# splitting the data into training, validation, and test sets (60-20-20 split).\n",
    "X = data.drop('Price', axis=1)\n",
    "y = data['Price']\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding and Scaling\n",
    "# We use OneHotEncoder for categorical variables and StandardScaler for numerical features.\n",
    "ohe = OneHotEncoder(drop=None, sparse=False, handle_unknown='ignore')\n",
    "X_train_encoded = pd.DataFrame(ohe.fit_transform(X_train[categorical_cols]))\n",
    "X_valid_encoded = pd.DataFrame(ohe.transform(X_valid[categorical_cols]))\n",
    "X_test_encoded = pd.DataFrame(ohe.transform(X_test[categorical_cols]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment 2 </b>\n",
    "    \n",
    "I see the updates, good!     \n",
    "</div>\n",
    "<div style=\"border: 5px solid gold; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment 2 </b>\n",
    "    \n",
    "Consider using different encoders for different models. As I said last time, For tree-based models, `OrdinalEncoder` is a better choice because of computational cost.    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "Yes, we need to encode data here, well done! It is acceptable to use `get_dummies` in this project, and we have to use it before you split the data because if we use it after we divide the data, we may face the situation where subsest have different number of categories.\n",
    "    \n",
    "</div>\n",
    "<div style=\"border: 5px solid gold; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "- Please note that `OneHotEncoder(handle_unknown='ignore')` can handle situations where test subset has features that were not available during training. \n",
    "    \n",
    "    \n",
    "    \n",
    "- For tree-based models, `OrdinalEncoder` is a better choice because of computational cost. For boosting algorithms, we can rely on internal encoders that usually perform even better than external ones. For `CatBoost`, this is controlled by the `cat_features` parameter. For `LightGBM`, you can convert categorical features to the category type, allowing the model to handle them automatically.\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "- `OrdinalEncoder()` or `LabelEncoder()` should not be used with linear models if there's no ordinal relationship. [How and When to Use Ordinal Encoder](https://leochoi146.medium.com/how-and-when-to-use-ordinal-encoder-d8b0ef90c28c).F or linear regresison, I recommend using `OneHotEncoder(handle_unknown='ignore')`. \n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"border: 5px solid red; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "- Please encode the data after you split it.\n",
    "\n",
    "\n",
    "- Consider excluding rare categories and deleting extra columns, which I mentioned earlier, to decrease computational cost. The kernel crashes at this point because the data is too large. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation Completed.\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_valid_scaled = scaler.transform(X_valid_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)\n",
    "\n",
    "print('Data Preparation Completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "It's great that you scale data after you split it to avoid data leakage. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Encoding and Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Training Time: 4.62 seconds\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "start_time = time.time()\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "end_time = time.time()\n",
    "lr_training_time = end_time - start_time\n",
    "print(f'Linear Regression Training Time: {lr_training_time:.2f} seconds')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment 3</b>\n",
    "    \n",
    "    \n",
    "Good. </div><div style=\"border: 5px solid gold; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment 3</b>\n",
    "    \n",
    "When estimating a specific piece of code (fitting the model), I recommend that you don't include creating a model or calculating the metric value in this measurement, since these actions also take time. It's better to estimate the training time only:\n",
    "    \n",
    "    \n",
    "```python\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end_time = time.time()  \n",
    "```\n",
    "    \n",
    "</div>\n",
    "\n",
    "<div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment 2 </b>\n",
    "    \n",
    "   \n",
    "For each model in the this section, please estimate training time. Feel free to use the following code: \n",
    "\n",
    "```python\n",
    "start_time = time.time()\n",
    "model_name.fit(X_train, y_train)\n",
    "end_time = time.time()  \n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Time: 207.70 seconds\n"
     ]
    }
   ],
   "source": [
    "# Random Forrest \n",
    "start_time = time.time()\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "end_time = time.time()\n",
    "rf_training_time = end_time - start_time\n",
    "print(f'Random Forest Training Time: {rf_training_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.182367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 867\n",
      "[LightGBM] [Info] Number of data points in the train set: 141618, number of used features: 289\n",
      "[LightGBM] [Info] Start training from score 5175.624278\n",
      "LightGBM Training Time: 4.19 seconds\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "start_time = time.time()\n",
    "lgb_train = lgb.Dataset(X_train_scaled, y_train)\n",
    "params = {'objective': 'regression', 'metric': 'rmse', 'random_state': 42}\n",
    "lgbm = lgb.train(params, lgb_train, num_boost_round=100)\n",
    "end_time = time.time()\n",
    "lgbm_training_time = end_time - start_time\n",
    "print(f'LightGBM Training Time: {lgbm_training_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment 2</b>\n",
    "    \n",
    "Several models were traine here, very good! \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from time import time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Hyperparameter Tuning for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "start_time = time()\n",
    "rf_random = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
    "                               param_distributions=param_grid,\n",
    "                               n_iter=10, cv=3, random_state=42, n_jobs=-1)\n",
    "rf_random.fit(X_train_scaled, y_train)\n",
    "end_time = time()\n",
    "print(f\"Random Forest Hyperparameter Tuning Time: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Best parameters for Random Forest: {rf_random.best_params_}\")\n",
    "\n",
    "# Retrain with best parameters\n",
    "best_rf = rf_random.best_estimator_\n",
    "\n",
    "# Model Evaluation and Prediction Time\n",
    "models = {\n",
    "    'Linear Regression': lr,\n",
    "    'Random Forest': best_rf,\n",
    "    'LightGBM': lgbm\n",
    "}\n",
    "\n",
    "print(\"\\nModel Performance and Prediction Time:\")\n",
    "model_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pred_start = time()\n",
    "    y_pred = model.predict(X_valid_scaled)\n",
    "    pred_end = time()\n",
    "    rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "    pred_time = pred_end - pred_start\n",
    "    model_scores[name] = {'rmse': rmse, 'time': pred_time}\n",
    "    print(f\"{name} - RMSE: {rmse:.2f}, Prediction Time: {pred_time:.4f} sec\")\n",
    "\n",
    "# Step 3: Automatically Choose Best Model\n",
    "# Define RMSE threshold for \"close enough\" comparison\n",
    "rmse_values = [v['rmse'] for v in model_scores.values()]\n",
    "min_rmse = min(rmse_values)\n",
    "threshold = min_rmse * 1.01  # 1% difference allowed\n",
    "\n",
    "# Filter models within RMSE threshold, then pick the fastest\n",
    "close_models = {k: v for k, v in model_scores.items() if v['rmse'] <= threshold}\n",
    "best_model_name = min(close_models.items(), key=lambda x: x[1]['time'])[0]\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"\\n‚úÖ Best model selected automatically: {best_model_name}\")\n",
    "\n",
    "# Final Test Performance\n",
    "start_test = time()\n",
    "y_test_pred = best_model.predict(X_test_scaled)\n",
    "end_test = time()\n",
    "final_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "final_time = end_test - start_test\n",
    "\n",
    "print(f\"\\nüß™ Final Test Results for {best_model_name}:\")\n",
    "print(f\"Test RMSE: {final_rmse:.2f}\")\n",
    "print(f\"Prediction Time: {final_time:.4f} seconds\")\n",
    "\n",
    "# Overall Conclusion\n",
    "print(\"\\nüìå Overall Conclusion:\")\n",
    "print(\"Models Evaluated:\")\n",
    "for name, score in model_scores.items():\n",
    "    print(f\"- {name}: RMSE = {score['rmse']:.2f}, Time = {score['time']:.4f} sec\")\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"‚úî Final Test RMSE: {final_rmse:.2f}, Prediction Time: {final_time:.4f} sec\")\n",
    "print(\"‚úÖ Selected for its strong balance of accuracy and efficiency.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Findings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression had the fastest prediction time but the highest RMSE, making it less accurate for our target task.\n",
    "\n",
    "LightGBM performed very well in both accuracy and speed, with relatively low RMSE and fast predictions.\n",
    "\n",
    "Random Forest (after hyperparameter tuning) achieved the lowest RMSE, meaning it had the highest accuracy. However, its prediction time was slower than LightGBM's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment 4</b>\n",
    "    \n",
    "Good! \n",
    "</div>\n",
    "<div style=\"border: 5px solid gold; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment 4 </b>\n",
    "    \n",
    "It will be even better if you specify their RMSE and sppeed values so that a reader does not need to run your code in order to see the results. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model was Random Forest, as it achieved the lowest RMSE on both the validation and test sets.\n",
    "Although LightGBM was slightly faster in terms of prediction time, the gain in accuracy from Random Forest was significant enough to justify its use‚Äîespecially if the model will not be used in high-frequency real-time settings.\n",
    "\n",
    "Therefore, Random Forest (with tuned hyperparameters) was selected as the final model due to its superior prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment 4 </b>\n",
    "    \n",
    "Great job, thank you so mcuh! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment 3</b>\n",
    "    \n",
    "    \n",
    "You have successfully implemented hyperparameters tuning, well done!     \n",
    "</div>\n",
    "\n",
    "<div style=\"border: 5px solid gold; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment 3</b>\n",
    "    \n",
    "    \n",
    "- The `rf` model was not included in this comparison. It is still possible that this model, with hte default hyperparameters, performs better than the tuned forest. \n",
    "\n",
    "\n",
    "- The best model isn't always the one with the lowest error. Sometimes the errors are only slightly different, but the prediction time varies significantly. In such cases, it's worth considering a faster model. Think of a slow search engine that finds 10 useful links versus a fast one that finds 9. This is especially important if the model needs to operate in real time and produce results repeatedly. If a program runs just once, its speed might not even matter. But if it‚Äôs used continuously, optimization becomes crucial. So, in practice, apart from the other requirements, there are also runtime constraints for the model.\n",
    "\n",
    "\n",
    "</div>    \n",
    "\n",
    "\n",
    "<div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment 3</b>\n",
    "    \n",
    "- In your code below\n",
    "\n",
    "\n",
    "```python\n",
    "if name == 'LightGBM':\n",
    "    # LightGBM prediction\n",
    "    y_pred = model.predict(X_valid_scaled)\n",
    "else:\n",
    "    # Prediction for other models\n",
    "    y_pred = model.predict(X_valid_scaled)\n",
    "```\n",
    "and \n",
    "\n",
    "```python\n",
    "if best_model == 'LightGBM':\n",
    "    y_test_pred = models[best_model].predict(X_test_scaled)\n",
    "else:\n",
    "    y_test_pred = models[best_model].predict(X_test_scaled)\n",
    "end_test = time()\n",
    "```\n",
    "\n",
    "`if` and `else` are doing the same thing. You don't need to use `if-else` then, do you ? \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Please write the overall conclusion in the Markdown cell and describe the key results. What models did you test? What are their RMSE scores? What are their speed values? Why did you choose a specific model and how did it perform on the final test? \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid red; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment 2 </b>\n",
    "    \n",
    "- How does `if` case differ from the `else` case?\n",
    "\n",
    "- Please estimate prediction time here. This is one of the tasks :)\n",
    "\n",
    "\n",
    "\n",
    "Let me also repeat one of my comments here. You proobably did not see it because of these UI issues we experience after recent updates. Here's the comment: \n",
    "\n",
    "\n",
    "- Please try to tune hyperparameters for at least one of the models. For this purpose, use `RandomizedSearchCV` or `GridSearchCV`. If you decide to use a loop, don't forget to change the way you split the data, because in this case we will need three subsets, not two. \n",
    "    \n",
    "    \n",
    "    \n",
    "- After you train all models, please choose the best **one** and check its performance on the test subset. Here we only need to make predictions and calculate RMSE. For the final testing, where we use the test subset to check the model's generalization ability, we should use the best model (one model or two models if they have almost the same metric values). We don't use all models here because even just checking their performance influences our choices. This leads to test set leakage when we unconsciously start picking models that perform well on the test set, making it part of the training loop. In real-world scenarios, the test set is meant to reflect how the final model performs in the wild. In practice, you only deploy one model, not several models, so testing just that final one mirrors reality. Moreover, evaluating every tuned model on the test set (especially with big models or datasets) is expensive and time-consuming. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- When choosing the best model, please consider prediction time as well. The best model isn't always the one with the lowest error. Sometimes the errors are only slightly different, but the prediction time varies significantly. In such cases, it's worth considering a faster model. Think of a slow search engine that finds 10 useful links versus a fast one that finds 9. This is especially important if the model needs to operate in real time and produce results repeatedly. If a program runs just once, its speed might not even matter. But if it‚Äôs used continuously, optimization becomes crucial. So, in practice, apart from the other requirements, there are also runtime constraints for the model.\n",
    "\n",
    "\n",
    "- Let's add the overall conclusion to your project: what has been done and what can be inferred from the results. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "Good! \n",
    "</div><div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "- Please make sure you save at least one subset for the final testing. In the cell above, you split the data into 2 subsets. If one of the subsets must be saved for the final test and must not be touched, RMSE must be evaluated on the same subset you use for training. Or you can split the data into 3 subsets, not 2. \n",
    "    \n",
    "\n",
    "\n",
    "- One of the main goals here is to compare models' training and prediction speed. Would you please estimate them separately? \n",
    "\n",
    "</div>\n",
    "<div style=\"border: 5px solid gold; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "When estimating a specific piece of code (fitting the model), I recommend that you don't include creating a model or calculating the metric value in this measurement, since these actions also take time. It's better to estimate the training time only:\n",
    "    \n",
    "    \n",
    "```python\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end_time = time.time()  \n",
    "```\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "Same issue here and below: please do not use the test subset. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid gold; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "You can compare the results with a constant baseline. For instance, you can take [DummyRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html). \n",
    "\n",
    "</div>\n",
    "<div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "- Please try to tune hyperparameters for at least one of the models. For this purpose, use `RandomizedSearchCV` or `GridSearchCV`. If you decide to use a loop, don't forget to change the way you split the data, because in this case we will need three subsets, not two. \n",
    "    \n",
    "    \n",
    "    \n",
    "- After you train all models, please choose the best **one** and check its performance on the test subset. Here we only need to make predictions and calculate RMSE. For the final testing, where we use the test subset to check the model's generalization ability, we should use the best model (one model or two models if they have almost the same metric values). We don't use all models here because even just checking their performance influences our choices. This leads to test set leakage when we unconsciously start picking models that perform well on the test set, making it part of the training loop. In real-world scenarios, the test set is meant to reflect how the final model performs in the wild. In practice, you only deploy one model, not several models, so testing just that final one mirrors reality. Moreover, evaluating every tuned model on the test set (especially with big models or datasets) is expensive and time-consuming. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- When choosing the best model, please consider prediction time as well. The best model isn't always the one with the lowest error. Sometimes the errors are only slightly different, but the prediction time varies significantly. In such cases, it's worth considering a faster model. Think of a slow search engine that finds 10 useful links versus a fast one that finds 9. This is especially important if the model needs to operate in real time and produce results repeatedly. If a program runs just once, its speed might not even matter. But if it‚Äôs used continuously, optimization becomes crucial. So, in practice, apart from the other requirements, there are also runtime constraints for the model.\n",
    "\n",
    "\n",
    "- Let's add the overall conclusion to your project: what has been done and what can be inferred from the results. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type 'x' to check. Then press Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook is open\n",
    "- [ ]  Code is error free\n",
    "- [ ]  The cells with the code have been arranged in order of execution\n",
    "- [ ]  The data has been downloaded and prepared\n",
    "- [ ]  The models have been trained\n",
    "- [ ]  The analysis of speed and quality of the models has been performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
